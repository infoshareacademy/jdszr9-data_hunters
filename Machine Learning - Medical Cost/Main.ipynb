{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /usr/local/python/3.10.4/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from category_encoders) (0.13.5)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (1.24.2)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (2.0.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from category_encoders) (1.10.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2023.3)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.10/site-packages (from statsmodels>=0.9.0->category_encoders) (23.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: xgboost in /usr/local/python/3.10.4/lib/python3.10/site-packages (1.7.5)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from xgboost) (1.10.1)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from xgboost) (1.24.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from hyperopt) (1.10.1)\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cloudpickle\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from hyperopt) (1.24.2)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from hyperopt) (1.16.0)\n",
      "Collecting future\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.2 in /home/codespace/.local/lib/python3.10/site-packages (from hyperopt) (3.0)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492022 sha256=27dc428e2fac663b59877c1b7cdd849ef349219a82ce7875c44b54bd8b7874cf\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/5e/a9/47/f118e66afd12240e4662752cc22cefae5d97275623aa8ef57d\n",
      "Successfully built future\n",
      "Installing collected packages: py4j, tqdm, future, cloudpickle, hyperopt\n",
      "Successfully installed cloudpickle-2.2.1 future-0.18.3 hyperopt-0.2.7 py4j-0.10.9.7 tqdm-4.65.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade category_encoders\n",
    "!pip install xgboost\n",
    "!pip install hyperopt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_log_error, mean_squared_error, mean_absolute_error, r2_score\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import Pipeline\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import power_transform\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from hyperopt import tpe, STATUS_OK, Trials, hp, fmin, STATUS_OK, space_eval\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from hyperopt.pyll.base import scope\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_mean_absolute_percentage_error(a, f):\n",
    "    return 1/len(a) * np.sum(2 * np.abs(f-a) / (np.abs(a) + np.abs(f))*100)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, target_name):\n",
    "    y=df[target_name]\n",
    "    data_mean, data_std = mean(y), std(y)\n",
    "# identify outliers\n",
    "    cut_off = data_std * 3\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "# identify outliers\n",
    "\n",
    "    df_ = df[df[target_name].between(lower, upper)]\n",
    "    return df_\n",
    "\n",
    "def scaler(df):\n",
    "    ss=StandardScaler()\n",
    "    df_=ss.fit_transform(df)\n",
    "    return df_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_tag():\n",
    "    return {'Specific': [], 'MAPE': [], 'SMAPE':[],  'MSLE': [], 'MSE':[], 'MAE':[], 'R2':[]}\n",
    "\n",
    "def get_metrics(a, p, name):\n",
    "\n",
    "    metrics = {'MAPE' : mean_absolute_percentage_error, 'SMAPE': symmetric_mean_absolute_percentage_error, 'MSLE': mean_squared_log_error, 'MSE': mean_squared_error, 'MAE': mean_absolute_error, 'R2':r2_score}\n",
    "    tags=create_metrics_tag()\n",
    "\n",
    "    for metric in metrics.keys():\n",
    "        func=metrics[metric]\n",
    "        val =func(a, p)\n",
    "        tags[metric].append(val)\n",
    "\n",
    "    tags['Specific'].append(name)\n",
    "    df_ = pd.DataFrame(tags)\n",
    "    return df_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleColumns(dropCols= []):\n",
    "    CatColumns=['sex', 'smoker', 'region', 'weight', 'senility']\n",
    "    ValColumns=['bmi',  'multiplier', 'children', 'age']\n",
    "    catCols = [i for i in CatColumns if i not in dropCols]\n",
    "    valCols = [i for i in ValColumns if i not in dropCols]\n",
    "    return catCols, valCols\n",
    "\n",
    "def getPipe(model, dropCols= []):\n",
    "\n",
    "    catCols,valCols = handleColumns(dropCols)\n",
    "    encoder = ce.JamesSteinEncoder(cols=catCols)\n",
    "    ct = ColumnTransformer([\n",
    "        ('scaler', StandardScaler(), valCols+ catCols)\n",
    "    ], remainder='passthrough') \n",
    "\n",
    "    modelpipe = Pipeline([\n",
    "  ('encode_categorical', encoder),\n",
    "  ('transformer', ct),\n",
    "  ('classifier', model)\n",
    "  ])\n",
    "\n",
    "    return modelpipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df,scal= False, dropN= None ):\n",
    "\n",
    "    df_=df.copy()\n",
    "    if(dropN):\n",
    "        df_=df_.drop(dropN, axis=1)\n",
    "    df_['weight']= pd.cut(df_['bmi'], bins=[0, 18.5, 25, 30, 40 , float('Inf')], labels=['Underweight', 'Normal', 'Overweight', 'Obese', 'Ultra_obese '])\n",
    "    df_[df_['bmi']>35]\n",
    "    df_['senility']= pd.cut(df_['age'], bins=[0, 30, 50, 60,float('Inf')], labels=['Young_adults', 'Adults', 'Old_adults', 'Pensioners'])\n",
    "    df_['multiplier']= df_['age'] * df_['bmi']\n",
    "    x=df_.copy().drop('charges', axis=1)\n",
    "    y=df_['charges'].copy()\n",
    "    if(scal):\n",
    "        x = scaler(x)\n",
    "    return x, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Removed outliers\n",
    "- No Missing Values\n",
    "- Power Transform on target\n",
    "\n",
    "### Feature Engineering:\n",
    "- 'weight': categorical BMI\n",
    "- 'senility': categorical Age\n",
    "- 'multiplier': age * bmi\n",
    "\n",
    "### Pipeline:\n",
    "1. Categorical values: JamesSteinEncoder\n",
    "2. Numerical values: StandardScaler\n",
    "3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 9, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mhttps://www.kaggle.com/datasets/mirichoi0218/insurance?select=insurance.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m X,y\u001b[39m=\u001b[39mpreprocess(df, scal\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m \u001b[39m42\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m         nrows\n\u001b[1;32m   1706\u001b[0m     )\n\u001b[1;32m   1707\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:812\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:873\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:848\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:859\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:2025\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 9, saw 2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('archive\\insurance.csv')\n",
    "X,y=preprocess(df, scal=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Szukamy optymalnych parametrów poprzez kros - walidacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getModelDIc( model, dropCols = [] , powtransform= False):\n",
    "    \n",
    "\n",
    "  modelpipe = getPipe(model, dropCols)\n",
    "  \n",
    "  \n",
    "  return {'model': modelpipe, 'powerTransform': powtransform, 'drop': dropCols}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_dummy = pd.get_dummies(X_train, drop_first= True)\n",
    "X_dummy= pd.get_dummies(X_test, drop_first= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specific</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>SMAPE</th>\n",
       "      <th>MSLE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>0.529010</td>\n",
       "      <td>44.638105</td>\n",
       "      <td>1.485989</td>\n",
       "      <td>3.426320e+07</td>\n",
       "      <td>4317.969150</td>\n",
       "      <td>0.779301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear transformed full</td>\n",
       "      <td>0.283271</td>\n",
       "      <td>26.256579</td>\n",
       "      <td>0.181731</td>\n",
       "      <td>6.166631e+07</td>\n",
       "      <td>3953.534081</td>\n",
       "      <td>0.602790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear transformed without</td>\n",
       "      <td>0.284528</td>\n",
       "      <td>26.396397</td>\n",
       "      <td>0.183120</td>\n",
       "      <td>5.920472e+07</td>\n",
       "      <td>3940.640734</td>\n",
       "      <td>0.618646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tree</td>\n",
       "      <td>0.331120</td>\n",
       "      <td>28.100890</td>\n",
       "      <td>0.178438</td>\n",
       "      <td>2.109348e+07</td>\n",
       "      <td>2697.765431</td>\n",
       "      <td>0.864131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest transformed full randomsearch</td>\n",
       "      <td>0.192487</td>\n",
       "      <td>19.846059</td>\n",
       "      <td>0.129524</td>\n",
       "      <td>2.181908e+07</td>\n",
       "      <td>2326.851847</td>\n",
       "      <td>0.859457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest transformed  without randomsearch</td>\n",
       "      <td>0.179542</td>\n",
       "      <td>18.452904</td>\n",
       "      <td>0.128546</td>\n",
       "      <td>1.891483e+07</td>\n",
       "      <td>1962.318951</td>\n",
       "      <td>0.878164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest transformed  without randomsearc...</td>\n",
       "      <td>0.182685</td>\n",
       "      <td>18.827000</td>\n",
       "      <td>0.126999</td>\n",
       "      <td>1.903440e+07</td>\n",
       "      <td>2063.244743</td>\n",
       "      <td>0.877394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF hyperopted transformed full</td>\n",
       "      <td>0.166282</td>\n",
       "      <td>17.653312</td>\n",
       "      <td>0.122768</td>\n",
       "      <td>1.826791e+07</td>\n",
       "      <td>1939.920439</td>\n",
       "      <td>0.882331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF hyperopted transformed without  region&amp;mult...</td>\n",
       "      <td>0.173471</td>\n",
       "      <td>18.223804</td>\n",
       "      <td>0.123695</td>\n",
       "      <td>1.882772e+07</td>\n",
       "      <td>2050.664907</td>\n",
       "      <td>0.878725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF hyperopted transformed without</td>\n",
       "      <td>0.182492</td>\n",
       "      <td>18.823064</td>\n",
       "      <td>0.127118</td>\n",
       "      <td>1.907494e+07</td>\n",
       "      <td>2066.787136</td>\n",
       "      <td>0.877133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost hyperopted</td>\n",
       "      <td>0.157065</td>\n",
       "      <td>17.637683</td>\n",
       "      <td>0.130161</td>\n",
       "      <td>2.630496e+07</td>\n",
       "      <td>2424.979979</td>\n",
       "      <td>0.830562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost hyperopted 2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>82.625774</td>\n",
       "      <td>3.234260e+08</td>\n",
       "      <td>12968.317063</td>\n",
       "      <td>-1.083276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Specific      MAPE       SMAPE  \\\n",
       "0                                            Linear    0.529010   44.638105   \n",
       "1                            Linear transformed full   0.283271   26.256579   \n",
       "2                          Linear transformed without  0.284528   26.396397   \n",
       "3                                                Tree  0.331120   28.100890   \n",
       "4         Random Forest transformed full randomsearch  0.192487   19.846059   \n",
       "5     Random Forest transformed  without randomsearch  0.179542   18.452904   \n",
       "6   Random Forest transformed  without randomsearc...  0.182685   18.827000   \n",
       "7                      RF hyperopted transformed full  0.166282   17.653312   \n",
       "8   RF hyperopted transformed without  region&mult...  0.173471   18.223804   \n",
       "9                   RF hyperopted transformed without  0.182492   18.823064   \n",
       "10                                 XGBoost hyperopted  0.157065   17.637683   \n",
       "11                               XGBoost hyperopted 2  1.000000  200.000000   \n",
       "\n",
       "         MSLE           MSE           MAE        R2  \n",
       "0    1.485989  3.426320e+07   4317.969150  0.779301  \n",
       "1    0.181731  6.166631e+07   3953.534081  0.602790  \n",
       "2    0.183120  5.920472e+07   3940.640734  0.618646  \n",
       "3    0.178438  2.109348e+07   2697.765431  0.864131  \n",
       "4    0.129524  2.181908e+07   2326.851847  0.859457  \n",
       "5    0.128546  1.891483e+07   1962.318951  0.878164  \n",
       "6    0.126999  1.903440e+07   2063.244743  0.877394  \n",
       "7    0.122768  1.826791e+07   1939.920439  0.882331  \n",
       "8    0.123695  1.882772e+07   2050.664907  0.878725  \n",
       "9    0.127118  1.907494e+07   2066.787136  0.877133  \n",
       "10   0.130161  2.630496e+07   2424.979979  0.830562  \n",
       "11  82.625774  3.234260e+08  12968.317063 -1.083276  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame(create_metrics_tag())\n",
    "\n",
    "models={}\n",
    "\n",
    "name='Linear'\n",
    "model= LinearRegression()\n",
    "dropCols=[]\n",
    "models[name]=getModelDIc( model ,dropCols)\n",
    "\n",
    "\n",
    "name='Tree'\n",
    "model= DecisionTreeRegressor(max_depth=4)\n",
    "dropCols=['multiplier', 'region', 'weight', 'senility', 'sex']\n",
    "models[name]=getModelDIc( model, dropCols)\n",
    "\n",
    "\n",
    "name='RF RandomSearch'\n",
    "model= RandomForestRegressor(n_estimators= 1577,\n",
    " min_samples_split= 2,\n",
    " min_samples_leaf= 4,\n",
    " max_features='sqrt',\n",
    " max_depth = 10,\n",
    " bootstrap= True )\n",
    "dropCols=[]\n",
    "models[name]=getModelDIc( model, dropCols, True)\n",
    "\n",
    "\n",
    "\n",
    "name='RF HyperOpt'\n",
    "model= RandomForestRegressor(n_estimators = 1089, max_depth=29, min_samples_leaf=12, random_state=1, max_features=7)\n",
    "dropCols=[]\n",
    "models[name]=getModelDIc( model, dropCols, False)\n",
    "\n",
    "\n",
    "name='RF HyperOpt Tran'\n",
    "model= RandomForestRegressor(n_estimators = 1089, max_depth=29, min_samples_leaf=12, random_state=1, max_features=7)\n",
    "dropCols=[]\n",
    "models[name]=getModelDIc( model, dropCols, True)\n",
    "\n",
    "\n",
    "\n",
    "name='XGBRegressor HyperOpt'\n",
    "model = XGBRegressor(seed=0, learning_rate=  0.02754445567920848, max_depth= 3, n_estimators= 164)\n",
    "dropCols=[]\n",
    "models[name]=getModelDIc( model, dropCols, True)                    \n",
    "\n",
    "\n",
    "for modelN in models:\n",
    "\n",
    "    X_train_, X_test_, y_train_, y_test_= X_train, X_test, y_train, y_test\n",
    "    model=models[modelN]['model']\n",
    "    if(models[modelN]['powerTransform']):\n",
    "        y_train_=np.log1p(y_train_)\n",
    "    if(models[modelN]['drop']):\n",
    "        X_train_=X_train_.drop(models[modelN]['drop'], axis=1)\n",
    "        X_test_=X_test_.drop(models[modelN]['drop'], axis=1)\n",
    "    model.fit(X_train_, y_train_)\n",
    "\n",
    "    y_pred= model.predict(X_test_)\n",
    "    y_pred=np.where(y_pred>0, y_pred,0 )\n",
    "    if(models[modelN]['powerTransform']):\n",
    "        y_pred=np.expm1(y_pred)\n",
    "    \n",
    "    metric=get_metrics(y_test_, y_pred, modelN)\n",
    "    metrics = pd.concat([metrics, metric]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = (metrics2.MAPE<0.17).map({True: 'background-color: blue', False: ''})\n",
    "display(metrics2.style.apply(lambda s: color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsDF= metrics.set_index('Specific')\n",
    "metricNames=metricsDF.columns\n",
    "modelNames=metricsDF.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(11,11),nrows=2, ncols=3)\n",
    "ax1=plt.subplot(2,3,1)\n",
    "\n",
    "colors=['b', 'g', 'r', 'c', 'm', 'k']\n",
    "\n",
    "metricsDF[\"MAPE\"].plot(ax=axes[0,0], kind='bar', grid=True, title= 'MAPE', color=colors[0] )\n",
    "metricsDF[\"SMAPE\"].plot(ax=axes[0,1], kind='bar', grid=True, title= 'SMAPE' , color=colors[1])\n",
    "metricsDF[\"MSLE\"].plot(ax=axes[0,2], kind='bar', grid=True, title= 'MSLE', color=colors[2])\n",
    "metricsDF[\"MSE\"].plot(ax=axes[1,0], kind='bar', grid=True, title ='MSE', color=colors[3])\n",
    "metricsDF[\"MAE\"].plot(ax=axes[1,1], kind='bar', grid=True, title ='MAE', color=colors[4])\n",
    "metricsDF[\"R2\"].plot(ax=axes[1,2], kind='bar', grid=True, title ='R2', color=colors[5])\n",
    "\n",
    "\n",
    "ax1.grid(True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Optimalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics2 = pd.DataFrame(create_metrics_tag())\n",
    "\n",
    "models={}\n",
    "\n",
    "name='RF with weight '\n",
    "model= RandomForestRegressor(n_estimators = 1089, max_depth=29, min_samples_leaf=12, random_state=1, max_features=7)\n",
    "dropCols=['multiplier', 'senility']\n",
    "models[name]=getModelDIc( model, dropCols, True)\n",
    "\n",
    "name='XGBR with added'\n",
    "model = XGBRegressor(seed=0, learning_rate=  0.02754445567920848, max_depth= 3, n_estimators= 164)\n",
    "dropCols=[]\n",
    "models[name]=getModelDIc( model, dropCols, True)   \n",
    "\n",
    "name='XGBR without added'\n",
    "model = XGBRegressor(seed=0, learning_rate=  0.02754445567920848, max_depth= 3, n_estimators= 164)\n",
    "dropCols=['multiplier', 'senility', 'weight']\n",
    "models[name]=getModelDIc( model, dropCols, True)  \n",
    "\n",
    "name='XGBR with multiplier'\n",
    "model = XGBRegressor(seed=0, learning_rate=  0.02754445567920848, max_depth= 3, n_estimators= 164)\n",
    "dropCols=['weight']\n",
    "models[name]=getModelDIc( model, dropCols, True)  \n",
    "\n",
    "\n",
    "name='XGBR with senility'\n",
    "model = XGBRegressor(seed=0, learning_rate=  0.02754445567920848, max_depth= 3, n_estimators= 164)\n",
    "dropCols=['multiplier','weight']\n",
    "models[name]=getModelDIc( model, dropCols, True)  \n",
    "\n",
    "name='XGBR with multiplier'\n",
    "model = XGBRegressor(seed=0, learning_rate=  0.02754445567920848, max_depth= 3, n_estimators= 164)\n",
    "dropCols=['senility', 'weight']\n",
    "models[name]=getModelDIc( model, dropCols, True)  \n",
    "\n",
    "\n",
    "\n",
    "for modelN in models:\n",
    "\n",
    "    X_train_, X_test_, y_train_, y_test_= X_train, X_test, y_train, y_test\n",
    "    model=models[modelN]['model']\n",
    "    if(models[modelN]['powerTransform']):\n",
    "        y_train_=np.log1p(y_train_)\n",
    "    if(models[modelN]['drop']):\n",
    "        X_train_=X_train_.drop(models[modelN]['drop'], axis=1)\n",
    "        X_test_=X_test_.drop(models[modelN]['drop'], axis=1)\n",
    "    model.fit(X_train_, y_train_)\n",
    "\n",
    "    y_pred= model.predict(X_test_)\n",
    "    y_pred=np.where(y_pred>0, y_pred,0 )\n",
    "    if(models[modelN]['powerTransform']):\n",
    "        y_pred=np.expm1(y_pred)\n",
    "    \n",
    "    metric=get_metrics(y_test_, y_pred, modelN)\n",
    "    metrics2 = pd.concat([metrics2, metric]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = (metrics2.MAPE<0.15).map({True: 'background-color: blue', False: ''})\n",
    "display(metrics2.style.apply(lambda s: color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsDF2= metrics2.set_index('Specific')\n",
    "metricNames2=metricsDF2.columns\n",
    "modelNames2=metricsDF2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,10),nrows=2, ncols=3)\n",
    "ax1=plt.subplot(2,3,1)\n",
    "\n",
    "colors=['b', 'y', 'r', 'c', 'm', 'k']\n",
    "\n",
    "highlight = 'XGBR without multiplier'\n",
    "pos = metricsDF2.index.get_loc(highlight)\n",
    "\n",
    "metricsDF2[\"MAPE\"].plot(ax=axes[0,0], kind='bar', grid=True, title= 'MAPE', color=colors[0] )\n",
    "metricsDF2[\"SMAPE\"].plot(ax=axes[0,1], kind='bar', grid=True, title= 'SMAPE' , color=colors[1])\n",
    "metricsDF2[\"MSLE\"].plot(ax=axes[0,2], kind='bar', grid=True, title= 'MSLE', color=colors[2])\n",
    "metricsDF2[\"MSE\"].plot(ax=axes[1,0], kind='bar', grid=True, title ='MSE', color=colors[3])\n",
    "metricsDF2[\"MAE\"].plot(ax=axes[1,1], kind='bar', grid=True, title ='MAE', color=colors[4])\n",
    "metricsDF2[\"R2\"].plot(ax=axes[1,2], kind='bar', grid=True, title ='R2', color=colors[5])\n",
    "\n",
    "\n",
    "axes[0,0].patches[pos].set_facecolor('g')\n",
    "axes[0,1].patches[pos].set_facecolor('g')\n",
    "axes[0,2].patches[pos].set_facecolor('g')\n",
    "axes[1,0].patches[pos].set_facecolor('g')\n",
    "axes[1,1].patches[pos].set_facecolor('g')\n",
    "axes[1,2].patches[pos].set_facecolor('g')\n",
    "\n",
    "ax1.grid(True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics2 = pd.DataFrame(create_metrics_tag())\n",
    "\n",
    "models={}\n",
    "\n",
    "name='XGBR with sensilty'\n",
    "modelN = XGBRegressor(seed=66, learning_rate=  0.02754445567920848, max_depth= 3, n_estimators= 164)\n",
    "dropCols=['multiplier','weight' ]\n",
    "models[name]=getModelDIc( modelN, dropCols, True)  \n",
    "\n",
    "for modelN in models:\n",
    "\n",
    "    X_train_, X_test_, y_train_, y_test_= X_train, X_test, y_train, y_test\n",
    "    model=models[modelN]['model']\n",
    "    if(models[modelN]['powerTransform']):\n",
    "        y_train_=np.log1p(y_train_)\n",
    "    if(models[modelN]['drop']):\n",
    "        X_train_=X_train_.drop(models[modelN]['drop'], axis=1)\n",
    "        X_test_=X_test_.drop(models[modelN]['drop'], axis=1)\n",
    "    model.fit(X_train_, y_train_)\n",
    "    y_pred= model.predict(X_test_)\n",
    "    y_pred=np.where(y_pred>0, y_pred,0 )\n",
    "    if(models[modelN]['powerTransform']):\n",
    "        y_pred=np.expm1(y_pred)\n",
    "    \n",
    "    metric=get_metrics(y_test_, y_pred, modelN)\n",
    "    metrics2 = pd.concat([metrics2, metric]).reset_index(drop=True)\n",
    "    importances = model.named_steps[\"classifier\"].feature_importances_\n",
    "\n",
    "\n",
    "columns= X_train.columns\n",
    "columns = [i for i in columns if i not in dropCols]\n",
    "\n",
    "dfimportances=pd.DataFrame(data=importances.reshape(1,9- len(dropCols)), columns= columns)\n",
    "display(dfimportances)\n",
    "\n",
    "\n",
    "dfimportances.plot.bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models={}\n",
    "\n",
    "name='XGBR'\n",
    "modelN = XGBRegressor(seed=66, learning_rate=  0.02754445567920848, max_depth= 3, n_estimators= 164)\n",
    "dropCols=['multiplier','weight' ,'senility']\n",
    "models[name]=getModelDIc( modelN, dropCols, True)  \n",
    "\n",
    "for modelN in models:\n",
    "\n",
    "    X_train_, X_test_, y_train_, y_test_= X_train, X_test, y_train, y_test\n",
    "    model=models[modelN]['model']\n",
    "    if(models[modelN]['powerTransform']):\n",
    "        y_train_=np.log1p(y_train_)\n",
    "    if(models[modelN]['drop']):\n",
    "        X_train_=X_train_.drop(models[modelN]['drop'], axis=1)\n",
    "        X_test_=X_test_.drop(models[modelN]['drop'], axis=1)\n",
    "    model.fit(X_train_, y_train_)\n",
    "    y_pred= model.predict(X_test_)\n",
    "    y_pred=np.where(y_pred>0, y_pred,0 )\n",
    "    if(models[modelN]['powerTransform']):\n",
    "        y_pred=np.expm1(y_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "columns= X_train.columns\n",
    "columns = [i for i in columns if i not in dropCols]\n",
    "\n",
    "Trials= pd.DataFrame(columns=columns )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists=[]\n",
    "lists.append( [24, 'male', 23, 1, 'yes', 'southeast'])\n",
    "lists.append([35, 'female', 33, 2, 'no', 'northwest'])\n",
    "lists.append( [59, 'female', 25, 1, 'no', 'southeast'])\n",
    "lists.append([63, 'male', 30, 2, 'yes', 'northwest'])\n",
    "\n",
    "for list in lists:\n",
    "    Trials= Trials.append(pd.DataFrame([list], columns= columns), ignore_index=True)\n",
    "\n",
    "y_pred= model.predict(Trials)\n",
    "y_pred=np.where(y_pred>0, y_pred,0 )\n",
    "y_pred=np.expm1(y_pred)\n",
    "\n",
    "Trials['charges']= y_pred\n",
    "Trials\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#RandomSearchGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "space_rf = {\"max_depth\": hp.randint('max_depth', 1, 100),\n",
    "             \"n_estimators\": scope.int(hp.qloguniform('n_estimators', 1, 10, 1)),\n",
    "             \"min_samples_leaf\": hp.randint('min_samples_leaf', 1, 50),\n",
    "             \"max_features\": hp.choice('max_features', ['sqrt', 2, 3, 4, 5, 6, 7, 8]),\n",
    "             }\n",
    "def minimize_rf(params):\n",
    "    max_depth = params[\"max_depth\"]\n",
    "    max_features = params['max_features']\n",
    "    min_samples = params['min_samples_leaf']\n",
    "    n_estimators = int(params['n_estimators'])\n",
    "    model = getPipe(RandomForestRegressor(max_depth=max_depth, max_features=max_features, min_samples_leaf=min_samples, n_estimators=n_estimators))\n",
    "    mean_cv_score = np.mean(cross_val_score(model, X_train, y_train))\n",
    "    return -mean_cv_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [05:55<00:00, 17.79s/trial, best loss: -0.8492072062836253]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 47,\n",
       " 'max_features': 5,\n",
       " 'min_samples_leaf': 12,\n",
       " 'n_estimators': 2639.0}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf = fmin(minimize_rf, space_rf, max_evals=20, algo=tpe.suggest)\n",
    "best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8792472964158641"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_rf_regressor = RandomForestRegressor(n_estimators = 365, max_depth=47, min_samples_leaf=6, random_state=1)\n",
    "{'max_depth': 47,\n",
    " 'max_features': 5,\n",
    " 'min_samples_leaf': 12,\n",
    " 'n_estimators': 2639.0}\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 2639, max_depth=47, min_samples_leaf=12, random_state=1, max_features=5)\n",
    "best_rf_regressor = getPipe(model)\n",
    "best_rf_regressor.fit(X_train, y_train)\n",
    "y_pred_best = best_rf_regressor.predict(X_test)\n",
    "r2_score(y_test, y_pred_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>weight</th>\n",
       "      <th>senility</th>\n",
       "      <th>multiplier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.079161</td>\n",
       "      <td>0.074294</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>0.062669</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.695223</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>0.060741</td>\n",
       "      <td>0.014091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi  children    smoker    region    weight  \\\n",
       "0  0.079161  0.074294  0.008274  0.062669  0.002005  0.695223  0.003543   \n",
       "\n",
       "   senility  multiplier  \n",
       "0  0.060741    0.014091  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = best_rf_regressor.named_steps[\"classifier\"].feature_importances_\n",
    "\n",
    "\n",
    "pd.DataFrame(data=importances.reshape(1,9), columns= X_train.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hyperopt XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': hp.quniform(\"n_estimators\", 3, 18, 1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.3),\n",
    "    'max_depth': scope.int(hp.quniform(\"max_depth\", 3, 18, 1)),\n",
    "    'gamma': scope.int(hp.uniform ('gamma', 1,9)),\n",
    "    'reg_alpha' : scope.int(hp.quniform('reg_alpha', 40,180,1)),\n",
    "    'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "     'min_child_weight' : scope.int(hp.quniform('min_child_weight', 0, 10, 1)),\n",
    "    'n_estimators': scope.int(hp.quniform(\"n_estimators\", 3, 18, 1))\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:02<00:00, 22.98trial/s, best loss: -0.8492629086004975]\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    \n",
    "    xgboost = XGBRegressor(seed=0, **params)\n",
    "    score = cross_val_score(estimator=xgboost, \n",
    "                            X=X_trains, \n",
    "                            y=y_train, \n",
    "                            cv=3, \n",
    "                            n_jobs=-1).mean()\n",
    "    # Loss is negative score\n",
    "    loss = - score\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = 60, trials = Trials())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9108343039685818, 'gamma': 7, 'learning_rate': 0.23825571365013604, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 16, 'reg_alpha': 94, 'reg_lambda': 0.4490642002880383}\n"
     ]
    }
   ],
   "source": [
    "print(space_eval(space, best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1  value for the xgboost Bayesian optimization is 18574143.1462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8803588089401068"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_bo = XGBRegressor(seed=0, \n",
    "                           learning_rate=space_eval(space, best)['learning_rate'], \n",
    "                           max_depth=space_eval(space, best)['max_depth'], \n",
    "                           n_estimators=space_eval(space, best)['n_estimators'],\n",
    "                           ).fit(X_trains,y_train)\n",
    "# Make prediction using the best model\n",
    "bayesian_opt_predict = xgboost_bo.predict(X_tests)\n",
    "# Get performance metrics\n",
    "f1s = mean_squared_error(y_test, bayesian_opt_predict)\n",
    "# Print result\n",
    "print(f'The f1  value for the xgboost Bayesian optimization is {f1s:.4f}')\n",
    "\n",
    "xgboost_bo.score(X_tests, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
