{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_log_error, mean_squared_error, mean_absolute_error, r2_score\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import Pipeline\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import power_transform\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from hyperopt import tpe, STATUS_OK, Trials, hp, fmin, STATUS_OK, space_eval\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from hyperopt.pyll.base import scope\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_mean_absolute_percentage_error(a, f):\n",
    "    return 1/len(a) * np.sum(2 * np.abs(f-a) / (np.abs(a) + np.abs(f))*100)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, target_name):\n",
    "    y=df[target_name]\n",
    "    data_mean, data_std = mean(y), std(y)\n",
    "# identify outliers\n",
    "    cut_off = data_std * 3\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "# identify outliers\n",
    "\n",
    "    df_ = df[df[target_name].between(lower, upper)]\n",
    "    return df_\n",
    "\n",
    "def scaler(df):\n",
    "    ss=StandardScaler()\n",
    "    df_=ss.fit_transform(df)\n",
    "    return df_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_tag():\n",
    "    return {'Specific': [], 'MAPE': [], 'SMAPE':[],  'MSLE': [], 'MSE':[], 'MAE':[], 'R2':[]}\n",
    "\n",
    "def get_metrics(a, p, name):\n",
    "\n",
    "    metrics = {'MAPE' : mean_absolute_percentage_error, 'SMAPE': symmetric_mean_absolute_percentage_error, 'MSLE': mean_squared_log_error, 'MSE': mean_squared_error, 'MAE': mean_absolute_error, 'R2':r2_score}\n",
    "    tags=create_metrics_tag()\n",
    "\n",
    "    for metric in metrics.keys():\n",
    "        func=metrics[metric]\n",
    "        val =func(a, p)\n",
    "        tags[metric].append(val)\n",
    "\n",
    "    tags['Specific'].append(name)\n",
    "    df_ = pd.DataFrame(tags)\n",
    "    return df_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleColumns(dropCols= []):\n",
    "    CatColumns=['sex', 'smoker', 'region', 'weight', 'senility']\n",
    "    ValColumns=['bmi',  'multiplier', 'children', 'age']\n",
    "    catCols = [i for i in CatColumns if i not in dropCols]\n",
    "    valCols = [i for i in ValColumns if i not in dropCols]\n",
    "    return catCols, valCols\n",
    "\n",
    "def getPipe(model, dropCols= []):\n",
    "\n",
    "    catCols,valCols = handleColumns(dropCols)\n",
    "    encoder = ce.JamesSteinEncoder(cols=catCols)\n",
    "    ct = ColumnTransformer([\n",
    "        ('scaler', StandardScaler(), valCols+ catCols)\n",
    "    ], remainder='passthrough') \n",
    "\n",
    "    modelpipe = Pipeline([\n",
    "  ('encode_categorical', encoder),\n",
    "  ('transformer', ct),\n",
    "  ('classifier', model)\n",
    "  ])\n",
    "\n",
    "    return modelpipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df,scal= False, dropN= None ):\n",
    "\n",
    "    df_=df.copy()\n",
    "    if(dropN):\n",
    "        df_=df_.drop(dropN, axis=1)\n",
    "    df_['weight']= pd.cut(df_['bmi'], bins=[0, 18.5, 25, 30, 40 , float('Inf')], labels=['Underweight', 'Normal', 'Overweight', 'Obese', 'Ultra_obese '])\n",
    "    df_[df_['bmi']>35]\n",
    "    df_['senility']= pd.cut(df_['age'], bins=[0, 30, 50, 60,float('Inf')], labels=['Young_adults', 'Adults', 'Old_adults', 'Pensioners'])\n",
    "    df_['multiplier']= df_['age'] * df_['bmi']\n",
    "    x=df_.copy().drop('charges', axis=1)\n",
    "    y=df_['charges'].copy()\n",
    "    if(scal):\n",
    "        x = scaler(x)\n",
    "    return x, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('archive\\insurance.csv')\n",
    "X,y=preprocess(df, scal=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Szukamy optymalnych parametr√≥w poprzez kros - walidacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getModelDIc( model, dropCols = [] , powtransform= False):\n",
    "    \n",
    "\n",
    "  modelpipe = getPipe(model, dropCols)\n",
    "  \n",
    "  \n",
    "  return {'model': modelpipe, 'powerTransform': powtransform, 'drop': dropCols}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_dummy = pd.get_dummies(X_train, drop_first= True)\n",
    "X_dummy= pd.get_dummies(X_test, drop_first= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specific</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>SMAPE</th>\n",
       "      <th>MSLE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>0.529010</td>\n",
       "      <td>44.638105</td>\n",
       "      <td>1.485989</td>\n",
       "      <td>3.426320e+07</td>\n",
       "      <td>4317.969150</td>\n",
       "      <td>0.779301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear transformed full</td>\n",
       "      <td>0.283271</td>\n",
       "      <td>26.256579</td>\n",
       "      <td>0.181731</td>\n",
       "      <td>6.166631e+07</td>\n",
       "      <td>3953.534081</td>\n",
       "      <td>0.602790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear transformed without</td>\n",
       "      <td>0.284528</td>\n",
       "      <td>26.396397</td>\n",
       "      <td>0.183120</td>\n",
       "      <td>5.920472e+07</td>\n",
       "      <td>3940.640734</td>\n",
       "      <td>0.618646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tree</td>\n",
       "      <td>0.331120</td>\n",
       "      <td>28.100890</td>\n",
       "      <td>0.178438</td>\n",
       "      <td>2.109348e+07</td>\n",
       "      <td>2697.765431</td>\n",
       "      <td>0.864131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest transformed full randomsearch</td>\n",
       "      <td>0.192487</td>\n",
       "      <td>19.846059</td>\n",
       "      <td>0.129524</td>\n",
       "      <td>2.181908e+07</td>\n",
       "      <td>2326.851847</td>\n",
       "      <td>0.859457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest transformed  without randomsearch</td>\n",
       "      <td>0.179542</td>\n",
       "      <td>18.452904</td>\n",
       "      <td>0.128546</td>\n",
       "      <td>1.891483e+07</td>\n",
       "      <td>1962.318951</td>\n",
       "      <td>0.878164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest transformed  without randomsearc...</td>\n",
       "      <td>0.182685</td>\n",
       "      <td>18.827000</td>\n",
       "      <td>0.126999</td>\n",
       "      <td>1.903440e+07</td>\n",
       "      <td>2063.244743</td>\n",
       "      <td>0.877394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF hyperopted transformed full</td>\n",
       "      <td>0.166282</td>\n",
       "      <td>17.653312</td>\n",
       "      <td>0.122768</td>\n",
       "      <td>1.826791e+07</td>\n",
       "      <td>1939.920439</td>\n",
       "      <td>0.882331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF hyperopted transformed without  region&amp;mult...</td>\n",
       "      <td>0.173471</td>\n",
       "      <td>18.223804</td>\n",
       "      <td>0.123695</td>\n",
       "      <td>1.882772e+07</td>\n",
       "      <td>2050.664907</td>\n",
       "      <td>0.878725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF hyperopted transformed without</td>\n",
       "      <td>0.182492</td>\n",
       "      <td>18.823064</td>\n",
       "      <td>0.127118</td>\n",
       "      <td>1.907494e+07</td>\n",
       "      <td>2066.787136</td>\n",
       "      <td>0.877133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost hyperopted</td>\n",
       "      <td>0.157065</td>\n",
       "      <td>17.637683</td>\n",
       "      <td>0.130161</td>\n",
       "      <td>2.630496e+07</td>\n",
       "      <td>2424.979979</td>\n",
       "      <td>0.830562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost hyperopted 2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>82.625774</td>\n",
       "      <td>3.234260e+08</td>\n",
       "      <td>12968.317063</td>\n",
       "      <td>-1.083276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Specific      MAPE       SMAPE  \\\n",
       "0                                            Linear    0.529010   44.638105   \n",
       "1                            Linear transformed full   0.283271   26.256579   \n",
       "2                          Linear transformed without  0.284528   26.396397   \n",
       "3                                                Tree  0.331120   28.100890   \n",
       "4         Random Forest transformed full randomsearch  0.192487   19.846059   \n",
       "5     Random Forest transformed  without randomsearch  0.179542   18.452904   \n",
       "6   Random Forest transformed  without randomsearc...  0.182685   18.827000   \n",
       "7                      RF hyperopted transformed full  0.166282   17.653312   \n",
       "8   RF hyperopted transformed without  region&mult...  0.173471   18.223804   \n",
       "9                   RF hyperopted transformed without  0.182492   18.823064   \n",
       "10                                 XGBoost hyperopted  0.157065   17.637683   \n",
       "11                               XGBoost hyperopted 2  1.000000  200.000000   \n",
       "\n",
       "         MSLE           MSE           MAE        R2  \n",
       "0    1.485989  3.426320e+07   4317.969150  0.779301  \n",
       "1    0.181731  6.166631e+07   3953.534081  0.602790  \n",
       "2    0.183120  5.920472e+07   3940.640734  0.618646  \n",
       "3    0.178438  2.109348e+07   2697.765431  0.864131  \n",
       "4    0.129524  2.181908e+07   2326.851847  0.859457  \n",
       "5    0.128546  1.891483e+07   1962.318951  0.878164  \n",
       "6    0.126999  1.903440e+07   2063.244743  0.877394  \n",
       "7    0.122768  1.826791e+07   1939.920439  0.882331  \n",
       "8    0.123695  1.882772e+07   2050.664907  0.878725  \n",
       "9    0.127118  1.907494e+07   2066.787136  0.877133  \n",
       "10   0.130161  2.630496e+07   2424.979979  0.830562  \n",
       "11  82.625774  3.234260e+08  12968.317063 -1.083276  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame(create_metrics_tag())\n",
    "\n",
    "models={}\n",
    "\n",
    "name='Linear  '\n",
    "model= LinearRegression()\n",
    "dropCols=[]\n",
    "models[name]=getModelDIc( model ,dropCols)\n",
    "\n",
    "name='Linear transformed full '\n",
    "model= LinearRegression()\n",
    "dropCols=[]\n",
    "models[name]=getModelDIc( model ,dropCols, True)\n",
    "\n",
    "\n",
    "\n",
    "name='Linear transformed without'\n",
    "model= LinearRegression()\n",
    "dropCols=['multiplier', 'region', 'weight', 'senility', 'sex']\n",
    "\n",
    "models[name]=getModelDIc( model ,dropCols, True)\n",
    "\n",
    "\n",
    "name='Tree'\n",
    "model= DecisionTreeRegressor(max_depth=4)\n",
    "dropCols=['multiplier', 'region', 'weight', 'senility', 'sex']\n",
    "models[name]=getModelDIc( model, dropCols)\n",
    "\n",
    "\n",
    "name='Random Forest transformed full randomsearch'\n",
    "model= RandomForestRegressor(n_estimators= 1577,\n",
    " min_samples_split= 2,\n",
    " min_samples_leaf= 4,\n",
    " max_features='sqrt',\n",
    " max_depth = 10,\n",
    " bootstrap= True )\n",
    "dropCols=[]\n",
    "models[name]=getModelDIc( model, dropCols, True)\n",
    "\n",
    "name='Random Forest transformed  without randomsearch'\n",
    "model= RandomForestRegressor(n_estimators= 1577,\n",
    " min_samples_split= 2,\n",
    " min_samples_leaf= 4,\n",
    " max_features='sqrt',\n",
    " max_depth = 10,\n",
    " bootstrap= True )\n",
    "dropCols=['multiplier', 'region', 'weight', 'senility', 'sex']\n",
    "models[name]=getModelDIc( model, dropCols, True)\n",
    "\n",
    "\n",
    "\n",
    "name='Random Forest transformed  without randomsearchNew'\n",
    "model= RandomForestRegressor(n_estimators = 2639, max_depth=47, min_samples_leaf=12, random_state=1, max_features=5)\n",
    "dropCols=['multiplier', 'region', 'weight', 'senility', 'sex']\n",
    "models[name]=getModelDIc( model, dropCols, True)\n",
    "\n",
    "\n",
    "name='RF hyperopted transformed full'\n",
    "model= RandomForestRegressor(n_estimators = 1089, max_depth=29, min_samples_leaf=12, random_state=1, max_features=7)\n",
    "dropCols=[]\n",
    "models[name]=getModelDIc( model, dropCols, True)\n",
    "\n",
    "name='RF hyperopted transformed without  region&multiplier'\n",
    "model= RandomForestRegressor(n_estimators = 1089, max_depth=29, min_samples_leaf=12, random_state=1, max_features=7)\n",
    "dropCols=['multiplier', 'region']\n",
    "models[name]=getModelDIc( model, dropCols, True)\n",
    "\n",
    "name='RF hyperopted transformed without'\n",
    "model= RandomForestRegressor(n_estimators = 1089, max_depth=29, min_samples_leaf=12, random_state=1, max_features=7)\n",
    "dropCols=['multiplier', 'region', 'weight', 'senility', 'sex']\n",
    "models[name]=getModelDIc( model, dropCols, True)\n",
    "\n",
    "name='XGBoost hyperopted'\n",
    "model = XGBRegressor(seed=0, learning_rate=  0.02754445567920848, max_depth= 3, n_estimators= 164).fit(X_trains,y_train)\n",
    "dropCols=[]\n",
    "models[name]=getModelDIc( model, dropCols, True)\n",
    "\n",
    "\n",
    "                           \n",
    "\n",
    "\n",
    "for modelN in models:\n",
    "    X_train_, X_test_, y_train_, y_test_= X_train, X_test, y_train, y_test\n",
    "    model=models[modelN]['model']\n",
    "    if(models[modelN]['powerTransform']):\n",
    "        y_train_=np.log1p(y_train_)\n",
    "    if(models[modelN]['drop']):\n",
    "        X_train_=X_train_.drop(models[modelN]['drop'], axis=1)\n",
    "        X_test_=X_test_.drop(models[modelN]['drop'], axis=1)\n",
    "    model.fit(X_train_, y_train_)\n",
    "\n",
    "    y_pred= model.predict(X_test_)\n",
    "    y_pred=np.where(y_pred>0, y_pred,0 )\n",
    "    if(models[modelN]['powerTransform']):\n",
    "        y_pred=np.expm1(y_pred)\n",
    "    \n",
    "    metric=get_metrics(y_test_, y_pred, modelN)\n",
    "    metrics = pd.concat([metrics, metric]).reset_index(drop=True)\n",
    "metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#RandomSearchGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "space_rf = {\"max_depth\": hp.randint('max_depth', 1, 100),\n",
    "             \"n_estimators\": scope.int(hp.qloguniform('n_estimators', 1, 10, 1)),\n",
    "             \"min_samples_leaf\": hp.randint('min_samples_leaf', 1, 50),\n",
    "             \"max_features\": hp.choice('max_features', ['sqrt', 2, 3, 4, 5, 6, 7, 8]),\n",
    "             }\n",
    "def minimize_rf(params):\n",
    "    max_depth = params[\"max_depth\"]\n",
    "    max_features = params['max_features']\n",
    "    min_samples = params['min_samples_leaf']\n",
    "    n_estimators = int(params['n_estimators'])\n",
    "    model = getPipe(RandomForestRegressor(max_depth=max_depth, max_features=max_features, min_samples_leaf=min_samples, n_estimators=n_estimators))\n",
    "    mean_cv_score = np.mean(cross_val_score(model, X_train, y_train))\n",
    "    return -mean_cv_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [05:55<00:00, 17.79s/trial, best loss: -0.8492072062836253]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 47,\n",
       " 'max_features': 5,\n",
       " 'min_samples_leaf': 12,\n",
       " 'n_estimators': 2639.0}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf = fmin(minimize_rf, space_rf, max_evals=20, algo=tpe.suggest)\n",
    "best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8792472964158641"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_rf_regressor = RandomForestRegressor(n_estimators = 365, max_depth=47, min_samples_leaf=6, random_state=1)\n",
    "{'max_depth': 47,\n",
    " 'max_features': 5,\n",
    " 'min_samples_leaf': 12,\n",
    " 'n_estimators': 2639.0}\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 2639, max_depth=47, min_samples_leaf=12, random_state=1, max_features=5)\n",
    "best_rf_regressor = getPipe(model)\n",
    "best_rf_regressor.fit(X_train, y_train)\n",
    "y_pred_best = best_rf_regressor.predict(X_test)\n",
    "r2_score(y_test, y_pred_best)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>weight</th>\n",
       "      <th>senility</th>\n",
       "      <th>multiplier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.079161</td>\n",
       "      <td>0.074294</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>0.062669</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.695223</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>0.060741</td>\n",
       "      <td>0.014091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi  children    smoker    region    weight  \\\n",
       "0  0.079161  0.074294  0.008274  0.062669  0.002005  0.695223  0.003543   \n",
       "\n",
       "   senility  multiplier  \n",
       "0  0.060741    0.014091  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = best_rf_regressor.named_steps[\"classifier\"].feature_importances_\n",
    "\n",
    "\n",
    "pd.DataFrame(data=importances.reshape(1,9), columns= X_train.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hyperopt XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': hp.quniform(\"n_estimators\", 3, 18, 1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.3),\n",
    "    'max_depth': scope.int(hp.quniform(\"max_depth\", 3, 18, 1)),\n",
    "    'gamma': scope.int(hp.uniform ('gamma', 1,9)),\n",
    "    'reg_alpha' : scope.int(hp.quniform('reg_alpha', 40,180,1)),\n",
    "    'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "     'min_child_weight' : scope.int(hp.quniform('min_child_weight', 0, 10, 1)),\n",
    "    'n_estimators': scope.int(hp.quniform(\"n_estimators\", 3, 18, 1))\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60/60 [00:02<00:00, 22.98trial/s, best loss: -0.8492629086004975]\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    \n",
    "    xgboost = XGBRegressor(seed=0, **params)\n",
    "    score = cross_val_score(estimator=xgboost, \n",
    "                            X=X_trains, \n",
    "                            y=y_train, \n",
    "                            cv=3, \n",
    "                            n_jobs=-1).mean()\n",
    "    # Loss is negative score\n",
    "    loss = - score\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = 60, trials = Trials())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9108343039685818, 'gamma': 7, 'learning_rate': 0.23825571365013604, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 16, 'reg_alpha': 94, 'reg_lambda': 0.4490642002880383}\n"
     ]
    }
   ],
   "source": [
    "print(space_eval(space, best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1  value for the xgboost Bayesian optimization is 18574143.1462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8803588089401068"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_bo = XGBRegressor(seed=0, \n",
    "                           learning_rate=space_eval(space, best)['learning_rate'], \n",
    "                           max_depth=space_eval(space, best)['max_depth'], \n",
    "                           n_estimators=space_eval(space, best)['n_estimators'],\n",
    "                           ).fit(X_trains,y_train)\n",
    "# Make prediction using the best model\n",
    "bayesian_opt_predict = xgboost_bo.predict(X_tests)\n",
    "# Get performance metrics\n",
    "f1s = mean_squared_error(y_test, bayesian_opt_predict)\n",
    "# Print result\n",
    "print(f'The f1  value for the xgboost Bayesian optimization is {f1s:.4f}')\n",
    "\n",
    "xgboost_bo.score(X_tests, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
